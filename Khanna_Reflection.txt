Reflect on how you currently manage your documents and code, particularly content associated with publishable work. Would it stand up to a reproducibility test? How do you think non-reproducibile research affects computational biology and bioinformatics? What about in your specific field of study?

Currently for our work, the documents being prepared for publication are moved back and forth with the authors and updated with the latest document number in the title manually. We are not dealing with any code as of now for publication work, but expect to start with bioinformatic analysis soon. Our current approach would make it challenging for independent researchers to reproduce, given that an updated file can be confused from a prior version. Not to mention that seperate authors could end up working on prior versions of the manuscript and not the latest versions.
A more efficient way to approach this would be to use version control programs, such as git commit commands to have the file updated as we progress in our work.
As is the case with us, any bioinformatic research that is conducted in a non-version controlled/non-reproducible manner would impact the ease with which the knowledge is being dessiminated. This means it would be more challenging to interpret and understand updates thus taking away to some extent the credibility of the work, not to mention the pain in reviewing it. Independent researchers would find it difficult to replicate the findings and thus complicated the advancement of science.
In our field of study, since we deal with enormour transcriptome data, it requires careful annotation and updation throughout the progress in the project. Additionally, such data should be made available for public access. If updated genomes are not made available, it takes away from progress in knowledge as our data is now being assembled to an out-dated genome. If there is a lack of updated data available, it causes problems with downstream research applications.

